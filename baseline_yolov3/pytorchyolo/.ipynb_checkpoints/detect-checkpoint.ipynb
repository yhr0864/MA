{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment information:\n",
      "System: Linux 4.18.0-305.65.1.el8_4.x86_64\n",
      "Not using the poetry package\n",
      "No git or repo found\n",
      "Command line arguments: Namespace(batch_size=1, classes='../data/detrac.names', conf_thres=0.5, images='../data/test_samples/images', img_size=416, model='../config/yolov3-tiny.cfg', n_cpu=12, nms_thres=0.4, output='./output', weights='./current_yolov3.pth')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting:   0%|          | 0/100 [00:00<?, ?it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Detecting:  94%|█████████▍| 94/100 [00:00<00:00, 157.39it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Detecting: 100%|██████████| 100/100 [00:01<00:00, 89.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image ../data/test_samples/images/img00023_MVI_40743.jpg:\n",
      "\t+ Label: car | Confidence: 0.8768\n",
      "\t+ Label: bus | Confidence: 0.6754\n",
      "\t+ Label: bus | Confidence: 0.5946\n",
      "Image ../data/test_samples/images/img00034_MVI_39361.jpg:\n",
      "\t+ Label: car | Confidence: 0.8432\n",
      "Image ../data/test_samples/images/img00038_MVI_39401.jpg:\n",
      "\t+ Label: car | Confidence: 0.8640\n",
      "\t+ Label: car | Confidence: 0.7911\n",
      "\t+ Label: car | Confidence: 0.5550\n",
      "\t+ Label: car | Confidence: 0.5179\n",
      "\t+ Label: car | Confidence: 0.5014\n",
      "Image ../data/test_samples/images/img00049_MVI_40891.jpg:\n",
      "\t+ Label: car | Confidence: 0.8538\n",
      "\t+ Label: car | Confidence: 0.8431\n",
      "\t+ Label: car | Confidence: 0.8232\n",
      "\t+ Label: car | Confidence: 0.8013\n",
      "\t+ Label: car | Confidence: 0.7909\n",
      "\t+ Label: car | Confidence: 0.7730\n",
      "\t+ Label: car | Confidence: 0.6478\n",
      "\t+ Label: car | Confidence: 0.5912\n",
      "Image ../data/test_samples/images/img00058_MVI_40773.jpg:\n",
      "\t+ Label: car | Confidence: 0.8246\n",
      "\t+ Label: car | Confidence: 0.7548\n",
      "Image ../data/test_samples/images/img00097_MVI_40863.jpg:\n",
      "\t+ Label: car | Confidence: 0.8601\n",
      "\t+ Label: car | Confidence: 0.6841\n",
      "\t+ Label: car | Confidence: 0.6720\n",
      "\t+ Label: bus | Confidence: 0.5722\n",
      "Image ../data/test_samples/images/img00124_MVI_39211.jpg:\n",
      "\t+ Label: car | Confidence: 0.8956\n",
      "\t+ Label: bus | Confidence: 0.8206\n",
      "\t+ Label: car | Confidence: 0.6745\n",
      "Image ../data/test_samples/images/img00127_MVI_40714.jpg:\n",
      "\t+ Label: car | Confidence: 0.8862\n",
      "\t+ Label: car | Confidence: 0.8482\n",
      "\t+ Label: car | Confidence: 0.8337\n",
      "\t+ Label: car | Confidence: 0.8264\n",
      "\t+ Label: car | Confidence: 0.8242\n",
      "\t+ Label: car | Confidence: 0.8063\n",
      "\t+ Label: car | Confidence: 0.7941\n",
      "\t+ Label: car | Confidence: 0.7423\n",
      "\t+ Label: car | Confidence: 0.7189\n",
      "\t+ Label: car | Confidence: 0.6440\n",
      "\t+ Label: car | Confidence: 0.6025\n",
      "\t+ Label: car | Confidence: 0.5976\n",
      "\t+ Label: car | Confidence: 0.5252\n",
      "Image ../data/test_samples/images/img00135_MVI_39511.jpg:\n",
      "\t+ Label: bus | Confidence: 0.9070\n",
      "Image ../data/test_samples/images/img00150_MVI_40854.jpg:\n",
      "\t+ Label: car | Confidence: 0.9527\n",
      "\t+ Label: car | Confidence: 0.9411\n",
      "\t+ Label: van | Confidence: 0.9063\n",
      "\t+ Label: car | Confidence: 0.8603\n",
      "\t+ Label: car | Confidence: 0.8482\n",
      "\t+ Label: car | Confidence: 0.8182\n",
      "\t+ Label: car | Confidence: 0.7987\n",
      "\t+ Label: car | Confidence: 0.6511\n",
      "\t+ Label: car | Confidence: 0.5246\n",
      "\t+ Label: bus | Confidence: 0.5032\n",
      "Image ../data/test_samples/images/img00171_MVI_40891.jpg:\n",
      "\t+ Label: car | Confidence: 0.8479\n",
      "\t+ Label: car | Confidence: 0.7551\n",
      "\t+ Label: car | Confidence: 0.7003\n",
      "\t+ Label: car | Confidence: 0.6897\n",
      "\t+ Label: car | Confidence: 0.6820\n",
      "\t+ Label: car | Confidence: 0.5093\n",
      "Image ../data/test_samples/images/img00181_MVI_40711.jpg:\n",
      "\t+ Label: car | Confidence: 0.8011\n",
      "\t+ Label: car | Confidence: 0.7359\n",
      "\t+ Label: car | Confidence: 0.6592\n",
      "\t+ Label: van | Confidence: 0.5118\n",
      "\t+ Label: car | Confidence: 0.5091\n",
      "Image ../data/test_samples/images/img00209_MVI_40762.jpg:\n",
      "\t+ Label: car | Confidence: 0.6377\n",
      "Image ../data/test_samples/images/img00216_MVI_39401.jpg:\n",
      "\t+ Label: car | Confidence: 0.9275\n",
      "\t+ Label: car | Confidence: 0.8866\n",
      "\t+ Label: car | Confidence: 0.8477\n",
      "\t+ Label: car | Confidence: 0.8456\n",
      "\t+ Label: car | Confidence: 0.8405\n",
      "\t+ Label: car | Confidence: 0.6904\n",
      "\t+ Label: van | Confidence: 0.6296\n",
      "\t+ Label: car | Confidence: 0.5702\n",
      "Image ../data/test_samples/images/img00240_MVI_40855.jpg:\n",
      "\t+ Label: car | Confidence: 0.9408\n",
      "\t+ Label: car | Confidence: 0.8994\n",
      "\t+ Label: car | Confidence: 0.8310\n",
      "\t+ Label: car | Confidence: 0.8084\n",
      "\t+ Label: van | Confidence: 0.8075\n",
      "\t+ Label: car | Confidence: 0.7914\n",
      "\t+ Label: car | Confidence: 0.7877\n",
      "\t+ Label: car | Confidence: 0.6831\n",
      "\t+ Label: car | Confidence: 0.6597\n",
      "\t+ Label: bus | Confidence: 0.6409\n",
      "\t+ Label: car | Confidence: 0.6175\n",
      "\t+ Label: car | Confidence: 0.5210\n",
      "Image ../data/test_samples/images/img00267_MVI_40891.jpg:\n",
      "\t+ Label: car | Confidence: 0.8854\n",
      "\t+ Label: car | Confidence: 0.8608\n",
      "\t+ Label: car | Confidence: 0.7447\n",
      "\t+ Label: car | Confidence: 0.6562\n",
      "\t+ Label: car | Confidence: 0.6483\n",
      "\t+ Label: car | Confidence: 0.6121\n",
      "Image ../data/test_samples/images/img00294_MVI_40854.jpg:\n",
      "\t+ Label: car | Confidence: 0.9032\n",
      "\t+ Label: car | Confidence: 0.8862\n",
      "\t+ Label: van | Confidence: 0.8379\n",
      "\t+ Label: car | Confidence: 0.7950\n",
      "\t+ Label: car | Confidence: 0.7558\n",
      "\t+ Label: bus | Confidence: 0.7464\n",
      "\t+ Label: car | Confidence: 0.6792\n",
      "\t+ Label: car | Confidence: 0.6744\n",
      "\t+ Label: car | Confidence: 0.5976\n",
      "\t+ Label: car | Confidence: 0.5769\n",
      "Image ../data/test_samples/images/img00304_MVI_40762.jpg:\n",
      "\t+ Label: car | Confidence: 0.6921\n",
      "\t+ Label: car | Confidence: 0.5078\n",
      "Image ../data/test_samples/images/img00306_MVI_40772.jpg:\n",
      "\t+ Label: car | Confidence: 0.8746\n",
      "\t+ Label: car | Confidence: 0.8382\n",
      "\t+ Label: car | Confidence: 0.7715\n",
      "\t+ Label: car | Confidence: 0.7466\n",
      "\t+ Label: car | Confidence: 0.6581\n",
      "\t+ Label: car | Confidence: 0.6306\n",
      "\t+ Label: car | Confidence: 0.5868\n",
      "Image ../data/test_samples/images/img00307_MVI_39511.jpg:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/slurm_tmpdir/job_21522517/ipykernel_524461/1238657765.py:188: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, ax = plt.subplots(1)\n",
      "/scratch/slurm_tmpdir/job_21522517/ipykernel_524461/1238657765.py:187: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t+ Label: car | Confidence: 0.7694\n",
      "\t+ Label: bus | Confidence: 0.5973\n",
      "\t+ Label: car | Confidence: 0.5525\n",
      "Image ../data/test_samples/images/img00317_MVI_40761.jpg:\n",
      "\t+ Label: car | Confidence: 0.6357\n",
      "Image ../data/test_samples/images/img00323_MVI_40903.jpg:\n",
      "\t+ Label: car | Confidence: 0.9062\n",
      "\t+ Label: car | Confidence: 0.8260\n",
      "\t+ Label: car | Confidence: 0.7906\n",
      "\t+ Label: car | Confidence: 0.6859\n",
      "\t+ Label: van | Confidence: 0.6460\n",
      "\t+ Label: car | Confidence: 0.6015\n",
      "\t+ Label: car | Confidence: 0.5764\n",
      "\t+ Label: bus | Confidence: 0.5641\n",
      "Image ../data/test_samples/images/img00341_MVI_40761.jpg:\n",
      "Image ../data/test_samples/images/img00343_MVI_39361.jpg:\n",
      "\t+ Label: car | Confidence: 0.6061\n",
      "\t+ Label: car | Confidence: 0.5884\n",
      "Image ../data/test_samples/images/img00343_MVI_40793.jpg:\n",
      "\t+ Label: car | Confidence: 0.6335\n",
      "\t+ Label: car | Confidence: 0.5991\n",
      "Image ../data/test_samples/images/img00358_MVI_40863.jpg:\n",
      "\t+ Label: car | Confidence: 0.8696\n",
      "\t+ Label: car | Confidence: 0.6918\n",
      "\t+ Label: car | Confidence: 0.6397\n",
      "Image ../data/test_samples/images/img00369_MVI_40901.jpg:\n",
      "\t+ Label: car | Confidence: 0.8859\n",
      "\t+ Label: car | Confidence: 0.8818\n",
      "\t+ Label: car | Confidence: 0.8393\n",
      "\t+ Label: car | Confidence: 0.7209\n",
      "\t+ Label: van | Confidence: 0.6554\n",
      "\t+ Label: car | Confidence: 0.6339\n",
      "\t+ Label: car | Confidence: 0.5028\n",
      "Image ../data/test_samples/images/img00379_MVI_40852.jpg:\n",
      "\t+ Label: car | Confidence: 0.9587\n",
      "\t+ Label: car | Confidence: 0.7719\n",
      "\t+ Label: car | Confidence: 0.7248\n",
      "\t+ Label: car | Confidence: 0.6725\n",
      "\t+ Label: car | Confidence: 0.5879\n",
      "Image ../data/test_samples/images/img00380_MVI_40775.jpg:\n",
      "\t+ Label: car | Confidence: 0.7529\n",
      "\t+ Label: car | Confidence: 0.7292\n",
      "\t+ Label: car | Confidence: 0.6015\n",
      "Image ../data/test_samples/images/img00386_MVI_40714.jpg:\n",
      "\t+ Label: car | Confidence: 0.9230\n",
      "\t+ Label: car | Confidence: 0.8718\n",
      "\t+ Label: car | Confidence: 0.8606\n",
      "\t+ Label: car | Confidence: 0.8439\n",
      "\t+ Label: car | Confidence: 0.8240\n",
      "\t+ Label: car | Confidence: 0.7942\n",
      "\t+ Label: car | Confidence: 0.7203\n",
      "\t+ Label: car | Confidence: 0.7121\n",
      "\t+ Label: car | Confidence: 0.5886\n",
      "\t+ Label: car | Confidence: 0.5576\n",
      "Image ../data/test_samples/images/img00392_MVI_40864.jpg:\n",
      "\t+ Label: car | Confidence: 0.8324\n",
      "\t+ Label: car | Confidence: 0.7968\n",
      "\t+ Label: car | Confidence: 0.7423\n",
      "\t+ Label: bus | Confidence: 0.6298\n",
      "\t+ Label: car | Confidence: 0.6197\n",
      "\t+ Label: car | Confidence: 0.5695\n",
      "Image ../data/test_samples/images/img00425_MVI_40793.jpg:\n",
      "\t+ Label: car | Confidence: 0.7249\n",
      "\t+ Label: car | Confidence: 0.6700\n",
      "\t+ Label: car | Confidence: 0.6431\n",
      "\t+ Label: car | Confidence: 0.6223\n",
      "Image ../data/test_samples/images/img00443_MVI_40771.jpg:\n",
      "\t+ Label: car | Confidence: 0.8700\n",
      "\t+ Label: car | Confidence: 0.7969\n",
      "\t+ Label: car | Confidence: 0.6149\n",
      "\t+ Label: car | Confidence: 0.6106\n",
      "\t+ Label: car | Confidence: 0.5575\n",
      "\t+ Label: van | Confidence: 0.5321\n",
      "Image ../data/test_samples/images/img00457_MVI_40863.jpg:\n",
      "\t+ Label: car | Confidence: 0.8551\n",
      "\t+ Label: car | Confidence: 0.7083\n",
      "\t+ Label: car | Confidence: 0.5734\n",
      "Image ../data/test_samples/images/img00470_MVI_40902.jpg:\n",
      "\t+ Label: car | Confidence: 0.7782\n",
      "\t+ Label: bus | Confidence: 0.6174\n",
      "\t+ Label: bus | Confidence: 0.6065\n",
      "Image ../data/test_samples/images/img00471_MVI_39501.jpg:\n",
      "\t+ Label: car | Confidence: 0.5395\n",
      "Image ../data/test_samples/images/img00494_MVI_39401.jpg:\n",
      "\t+ Label: car | Confidence: 0.8546\n",
      "\t+ Label: car | Confidence: 0.8373\n",
      "\t+ Label: bus | Confidence: 0.7962\n",
      "\t+ Label: car | Confidence: 0.6229\n",
      "\t+ Label: car | Confidence: 0.6182\n",
      "\t+ Label: car | Confidence: 0.5192\n",
      "Image ../data/test_samples/images/img00497_MVI_39031.jpg:\n",
      "\t+ Label: car | Confidence: 0.8993\n",
      "\t+ Label: car | Confidence: 0.8585\n",
      "\t+ Label: car | Confidence: 0.6518\n",
      "Image ../data/test_samples/images/img00523_MVI_39371.jpg:\n",
      "\t+ Label: car | Confidence: 0.8713\n",
      "\t+ Label: car | Confidence: 0.8259\n",
      "\t+ Label: car | Confidence: 0.7403\n",
      "\t+ Label: car | Confidence: 0.7003\n",
      "Image ../data/test_samples/images/img00543_MVI_40853.jpg:\n",
      "\t+ Label: car | Confidence: 0.8229\n",
      "\t+ Label: car | Confidence: 0.8044\n",
      "\t+ Label: van | Confidence: 0.7694\n",
      "\t+ Label: car | Confidence: 0.7436\n",
      "\t+ Label: car | Confidence: 0.7006\n",
      "\t+ Label: car | Confidence: 0.6832\n",
      "\t+ Label: car | Confidence: 0.6491\n",
      "\t+ Label: car | Confidence: 0.6225\n",
      "\t+ Label: car | Confidence: 0.6018\n",
      "\t+ Label: car | Confidence: 0.5759\n",
      "Image ../data/test_samples/images/img00583_MVI_40774.jpg:\n",
      "\t+ Label: car | Confidence: 0.8788\n",
      "\t+ Label: car | Confidence: 0.8758\n",
      "\t+ Label: car | Confidence: 0.8089\n",
      "\t+ Label: car | Confidence: 0.5680\n",
      "Image ../data/test_samples/images/img00593_MVI_40701.jpg:\n",
      "\t+ Label: car | Confidence: 0.9501\n",
      "\t+ Label: car | Confidence: 0.9140\n",
      "\t+ Label: car | Confidence: 0.9064\n",
      "\t+ Label: car | Confidence: 0.8885\n",
      "\t+ Label: car | Confidence: 0.8796\n",
      "\t+ Label: car | Confidence: 0.8741\n",
      "\t+ Label: bus | Confidence: 0.8655\n",
      "\t+ Label: car | Confidence: 0.8454\n",
      "\t+ Label: car | Confidence: 0.8106\n",
      "\t+ Label: car | Confidence: 0.7631\n",
      "\t+ Label: car | Confidence: 0.6684\n",
      "\t+ Label: car | Confidence: 0.5396\n",
      "Image ../data/test_samples/images/img00600_MVI_40763.jpg:\n",
      "Image ../data/test_samples/images/img00602_MVI_40905.jpg:\n",
      "\t+ Label: car | Confidence: 0.8075\n",
      "\t+ Label: car | Confidence: 0.7306\n",
      "\t+ Label: car | Confidence: 0.7204\n",
      "\t+ Label: van | Confidence: 0.6202\n",
      "\t+ Label: car | Confidence: 0.5706\n",
      "\t+ Label: car | Confidence: 0.5456\n",
      "Image ../data/test_samples/images/img00614_MVI_39051.jpg:\n",
      "\t+ Label: car | Confidence: 0.8308\n",
      "\t+ Label: car | Confidence: 0.6169\n",
      "Image ../data/test_samples/images/img00614_MVI_39361.jpg:\n",
      "\t+ Label: car | Confidence: 0.7409\n",
      "Image ../data/test_samples/images/img00620_MVI_39271.jpg:\n",
      "\t+ Label: car | Confidence: 0.8381\n",
      "\t+ Label: car | Confidence: 0.7672\n",
      "\t+ Label: car | Confidence: 0.6371\n",
      "\t+ Label: car | Confidence: 0.5582\n",
      "\t+ Label: bus | Confidence: 0.5536\n",
      "Image ../data/test_samples/images/img00624_MVI_39051.jpg:\n",
      "\t+ Label: car | Confidence: 0.8209\n",
      "\t+ Label: car | Confidence: 0.7691\n",
      "Image ../data/test_samples/images/img00634_MVI_40762.jpg:\n",
      "\t+ Label: car | Confidence: 0.7445\n",
      "\t+ Label: car | Confidence: 0.6617\n",
      "\t+ Label: car | Confidence: 0.5830\n",
      "Image ../data/test_samples/images/img00640_MVI_40904.jpg:\n",
      "\t+ Label: car | Confidence: 0.7393\n",
      "\t+ Label: car | Confidence: 0.6414\n",
      "Image ../data/test_samples/images/img00650_MVI_40793.jpg:\n",
      "\t+ Label: car | Confidence: 0.7560\n",
      "\t+ Label: car | Confidence: 0.7400\n",
      "\t+ Label: car | Confidence: 0.6189\n",
      "\t+ Label: car | Confidence: 0.5193\n",
      "Image ../data/test_samples/images/img00655_MVI_40855.jpg:\n",
      "\t+ Label: car | Confidence: 0.9316\n",
      "\t+ Label: car | Confidence: 0.9121\n",
      "\t+ Label: car | Confidence: 0.8650\n",
      "\t+ Label: car | Confidence: 0.8640\n",
      "\t+ Label: car | Confidence: 0.8300\n",
      "\t+ Label: car | Confidence: 0.7964\n",
      "\t+ Label: car | Confidence: 0.7582\n",
      "\t+ Label: car | Confidence: 0.7527\n",
      "\t+ Label: car | Confidence: 0.7424\n",
      "Image ../data/test_samples/images/img00686_MVI_40743.jpg:\n",
      "\t+ Label: van | Confidence: 0.8598\n",
      "\t+ Label: car | Confidence: 0.8057\n",
      "\t+ Label: car | Confidence: 0.8022\n",
      "\t+ Label: car | Confidence: 0.7500\n",
      "\t+ Label: car | Confidence: 0.5889\n",
      "\t+ Label: car | Confidence: 0.5142\n",
      "Image ../data/test_samples/images/img00693_MVI_39031.jpg:\n",
      "\t+ Label: car | Confidence: 0.7889\n",
      "Image ../data/test_samples/images/img00720_MVI_40892.jpg:\n",
      "\t+ Label: van | Confidence: 0.8269\n",
      "\t+ Label: car | Confidence: 0.7444\n",
      "\t+ Label: car | Confidence: 0.6583\n",
      "\t+ Label: car | Confidence: 0.6551\n",
      "\t+ Label: car | Confidence: 0.5933\n",
      "Image ../data/test_samples/images/img00727_MVI_40863.jpg:\n",
      "\t+ Label: car | Confidence: 0.8487\n",
      "\t+ Label: car | Confidence: 0.5812\n",
      "\t+ Label: bus | Confidence: 0.5343\n",
      "\t+ Label: car | Confidence: 0.5195\n",
      "Image ../data/test_samples/images/img00739_MVI_40853.jpg:\n",
      "\t+ Label: car | Confidence: 0.9151\n",
      "\t+ Label: car | Confidence: 0.8730\n",
      "\t+ Label: car | Confidence: 0.8645\n",
      "\t+ Label: car | Confidence: 0.8080\n",
      "\t+ Label: car | Confidence: 0.7877\n",
      "\t+ Label: car | Confidence: 0.7727\n",
      "\t+ Label: car | Confidence: 0.7388\n",
      "\t+ Label: car | Confidence: 0.6863\n",
      "\t+ Label: car | Confidence: 0.6540\n",
      "\t+ Label: car | Confidence: 0.6288\n",
      "\t+ Label: car | Confidence: 0.5414\n",
      "Image ../data/test_samples/images/img00745_MVI_40852.jpg:\n",
      "\t+ Label: car | Confidence: 0.8690\n",
      "\t+ Label: car | Confidence: 0.8521\n",
      "\t+ Label: car | Confidence: 0.7965\n",
      "\t+ Label: car | Confidence: 0.7843\n",
      "\t+ Label: van | Confidence: 0.7547\n",
      "\t+ Label: car | Confidence: 0.5750\n",
      "Image ../data/test_samples/images/img00756_MVI_40855.jpg:\n",
      "\t+ Label: car | Confidence: 0.8968\n",
      "\t+ Label: car | Confidence: 0.8457\n",
      "\t+ Label: car | Confidence: 0.7357\n",
      "\t+ Label: car | Confidence: 0.6854\n",
      "\t+ Label: car | Confidence: 0.6427\n",
      "\t+ Label: car | Confidence: 0.6266\n",
      "\t+ Label: car | Confidence: 0.5890\n",
      "\t+ Label: van | Confidence: 0.5259\n",
      "Image ../data/test_samples/images/img00765_MVI_40793.jpg:\n",
      "\t+ Label: car | Confidence: 0.8071\n",
      "\t+ Label: car | Confidence: 0.7060\n",
      "\t+ Label: car | Confidence: 0.6993\n",
      "\t+ Label: car | Confidence: 0.6811\n",
      "\t+ Label: car | Confidence: 0.5767\n",
      "\t+ Label: car | Confidence: 0.5209\n",
      "\t+ Label: car | Confidence: 0.5128\n",
      "Image ../data/test_samples/images/img00770_MVI_40905.jpg:\n",
      "\t+ Label: car | Confidence: 0.7468\n",
      "\t+ Label: car | Confidence: 0.7291\n",
      "\t+ Label: car | Confidence: 0.7253\n",
      "\t+ Label: van | Confidence: 0.6783\n",
      "\t+ Label: car | Confidence: 0.6154\n",
      "Image ../data/test_samples/images/img00777_MVI_40761.jpg:\n",
      "Image ../data/test_samples/images/img00847_MVI_39051.jpg:\n",
      "\t+ Label: car | Confidence: 0.6519\n",
      "\t+ Label: car | Confidence: 0.6462\n",
      "Image ../data/test_samples/images/img00852_MVI_40743.jpg:\n",
      "\t+ Label: car | Confidence: 0.8914\n",
      "\t+ Label: car | Confidence: 0.8594\n",
      "\t+ Label: car | Confidence: 0.8233\n",
      "\t+ Label: car | Confidence: 0.6160\n",
      "Image ../data/test_samples/images/img00861_MVI_40863.jpg:\n",
      "\t+ Label: car | Confidence: 0.8764\n",
      "\t+ Label: car | Confidence: 0.6604\n",
      "\t+ Label: car | Confidence: 0.6315\n",
      "Image ../data/test_samples/images/img00877_MVI_40864.jpg:\n",
      "\t+ Label: car | Confidence: 0.8117\n",
      "\t+ Label: van | Confidence: 0.7628\n",
      "\t+ Label: car | Confidence: 0.6333\n",
      "\t+ Label: car | Confidence: 0.6102\n",
      "\t+ Label: van | Confidence: 0.5723\n",
      "\t+ Label: bus | Confidence: 0.5077\n",
      "Image ../data/test_samples/images/img00926_MVI_39051.jpg:\n",
      "Image ../data/test_samples/images/img00949_MVI_40711.jpg:\n",
      "\t+ Label: car | Confidence: 0.7906\n",
      "Image ../data/test_samples/images/img00950_MVI_40701.jpg:\n",
      "\t+ Label: car | Confidence: 0.9532\n",
      "\t+ Label: car | Confidence: 0.9253\n",
      "\t+ Label: car | Confidence: 0.8724\n",
      "\t+ Label: car | Confidence: 0.8453\n",
      "\t+ Label: bus | Confidence: 0.7978\n",
      "\t+ Label: car | Confidence: 0.7142\n",
      "\t+ Label: car | Confidence: 0.6319\n",
      "\t+ Label: car | Confidence: 0.6298\n",
      "\t+ Label: car | Confidence: 0.6296\n",
      "\t+ Label: car | Confidence: 0.5735\n",
      "Image ../data/test_samples/images/img00966_MVI_40773.jpg:\n",
      "\t+ Label: car | Confidence: 0.8319\n",
      "\t+ Label: car | Confidence: 0.6878\n",
      "Image ../data/test_samples/images/img00986_MVI_40761.jpg:\n",
      "Image ../data/test_samples/images/img01008_MVI_39311.jpg:\n",
      "\t+ Label: car | Confidence: 0.8840\n",
      "\t+ Label: car | Confidence: 0.6359\n",
      "\t+ Label: car | Confidence: 0.5193\n",
      "Image ../data/test_samples/images/img01023_MVI_40903.jpg:\n",
      "\t+ Label: bus | Confidence: 0.7504\n",
      "\t+ Label: car | Confidence: 0.7439\n",
      "\t+ Label: car | Confidence: 0.5785\n",
      "\t+ Label: car | Confidence: 0.5633\n",
      "\t+ Label: car | Confidence: 0.5206\n",
      "Image ../data/test_samples/images/img01057_MVI_40742.jpg:\n",
      "\t+ Label: bus | Confidence: 0.7611\n",
      "\t+ Label: car | Confidence: 0.7100\n",
      "\t+ Label: car | Confidence: 0.5139\n",
      "\t+ Label: bus | Confidence: 0.5042\n",
      "Image ../data/test_samples/images/img01072_MVI_40855.jpg:\n",
      "\t+ Label: car | Confidence: 0.8705\n",
      "\t+ Label: car | Confidence: 0.8418\n",
      "\t+ Label: car | Confidence: 0.7415\n",
      "\t+ Label: car | Confidence: 0.5901\n",
      "Image ../data/test_samples/images/img01082_MVI_39371.jpg:\n",
      "\t+ Label: car | Confidence: 0.8097\n",
      "\t+ Label: car | Confidence: 0.7438\n",
      "\t+ Label: bus | Confidence: 0.5882\n",
      "Image ../data/test_samples/images/img01131_MVI_40763.jpg:\n",
      "Image ../data/test_samples/images/img01185_MVI_39311.jpg:\n",
      "\t+ Label: car | Confidence: 0.7897\n",
      "\t+ Label: car | Confidence: 0.5926\n",
      "\t+ Label: car | Confidence: 0.5425\n",
      "\t+ Label: car | Confidence: 0.5328\n",
      "\t+ Label: car | Confidence: 0.5223\n",
      "Image ../data/test_samples/images/img01185_MVI_40761.jpg:\n",
      "Image ../data/test_samples/images/img01195_MVI_40792.jpg:\n",
      "\t+ Label: car | Confidence: 0.5978\n",
      "\t+ Label: car | Confidence: 0.5868\n",
      "\t+ Label: car | Confidence: 0.5567\n",
      "Image ../data/test_samples/images/img01211_MVI_40742.jpg:\n",
      "\t+ Label: bus | Confidence: 0.7489\n",
      "\t+ Label: car | Confidence: 0.6968\n",
      "\t+ Label: bus | Confidence: 0.6657\n",
      "\t+ Label: car | Confidence: 0.5310\n",
      "Image ../data/test_samples/images/img01246_MVI_40863.jpg:\n",
      "\t+ Label: car | Confidence: 0.8491\n",
      "\t+ Label: car | Confidence: 0.6604\n",
      "\t+ Label: car | Confidence: 0.6009\n",
      "\t+ Label: car | Confidence: 0.5555\n",
      "Image ../data/test_samples/images/img01248_MVI_40742.jpg:\n",
      "\t+ Label: bus | Confidence: 0.7517\n",
      "\t+ Label: car | Confidence: 0.6878\n",
      "\t+ Label: bus | Confidence: 0.6065\n",
      "\t+ Label: car | Confidence: 0.5462\n",
      "Image ../data/test_samples/images/img01263_MVI_40793.jpg:\n",
      "\t+ Label: car | Confidence: 0.7907\n",
      "\t+ Label: car | Confidence: 0.7566\n",
      "\t+ Label: bus | Confidence: 0.5755\n",
      "Image ../data/test_samples/images/img01292_MVI_40712.jpg:\n",
      "\t+ Label: car | Confidence: 0.8517\n",
      "\t+ Label: car | Confidence: 0.8484\n",
      "\t+ Label: car | Confidence: 0.8358\n",
      "\t+ Label: car | Confidence: 0.7821\n",
      "\t+ Label: car | Confidence: 0.7739\n",
      "\t+ Label: car | Confidence: 0.6768\n",
      "\t+ Label: car | Confidence: 0.6757\n",
      "\t+ Label: car | Confidence: 0.5672\n",
      "Image ../data/test_samples/images/img01344_MVI_40761.jpg:\n",
      "\t+ Label: car | Confidence: 0.8022\n",
      "\t+ Label: car | Confidence: 0.7913\n",
      "\t+ Label: car | Confidence: 0.7886\n",
      "\t+ Label: car | Confidence: 0.6883\n",
      "Image ../data/test_samples/images/img01395_MVI_40771.jpg:\n",
      "\t+ Label: car | Confidence: 0.6780\n",
      "Image ../data/test_samples/images/img01401_MVI_40853.jpg:\n",
      "\t+ Label: car | Confidence: 0.9397\n",
      "\t+ Label: car | Confidence: 0.9178\n",
      "\t+ Label: car | Confidence: 0.9104\n",
      "\t+ Label: car | Confidence: 0.9072\n",
      "\t+ Label: car | Confidence: 0.8697\n",
      "\t+ Label: car | Confidence: 0.8104\n",
      "\t+ Label: car | Confidence: 0.8001\n",
      "\t+ Label: car | Confidence: 0.6766\n",
      "\t+ Label: car | Confidence: 0.6748\n",
      "\t+ Label: car | Confidence: 0.6107\n",
      "Image ../data/test_samples/images/img01405_MVI_40771.jpg:\n",
      "\t+ Label: car | Confidence: 0.6796\n",
      "Image ../data/test_samples/images/img01420_MVI_39211.jpg:\n",
      "\t+ Label: car | Confidence: 0.8734\n",
      "\t+ Label: car | Confidence: 0.7959\n",
      "Image ../data/test_samples/images/img01434_MVI_40763.jpg:\n",
      "Image ../data/test_samples/images/img01454_MVI_40762.jpg:\n",
      "Image ../data/test_samples/images/img01485_MVI_39211.jpg:\n",
      "Image ../data/test_samples/images/img01499_MVI_40712.jpg:\n",
      "\t+ Label: car | Confidence: 0.8140\n",
      "\t+ Label: car | Confidence: 0.8044\n",
      "\t+ Label: bus | Confidence: 0.7833\n",
      "\t+ Label: car | Confidence: 0.7706\n",
      "\t+ Label: car | Confidence: 0.7391\n",
      "\t+ Label: car | Confidence: 0.7295\n",
      "\t+ Label: car | Confidence: 0.6751\n",
      "\t+ Label: car | Confidence: 0.6671\n",
      "\t+ Label: car | Confidence: 0.6369\n",
      "\t+ Label: car | Confidence: 0.6337\n",
      "Image ../data/test_samples/images/img01519_MVI_40863.jpg:\n",
      "\t+ Label: car | Confidence: 0.9209\n",
      "\t+ Label: car | Confidence: 0.7613\n",
      "\t+ Label: bus | Confidence: 0.6581\n",
      "\t+ Label: car | Confidence: 0.6450\n",
      "\t+ Label: van | Confidence: 0.6214\n",
      "Image ../data/test_samples/images/img01522_MVI_40892.jpg:\n",
      "\t+ Label: car | Confidence: 0.8699\n",
      "\t+ Label: van | Confidence: 0.7448\n",
      "\t+ Label: car | Confidence: 0.6711\n",
      "\t+ Label: car | Confidence: 0.6628\n",
      "\t+ Label: car | Confidence: 0.6611\n",
      "\t+ Label: car | Confidence: 0.6240\n",
      "\t+ Label: bus | Confidence: 0.6238\n",
      "\t+ Label: car | Confidence: 0.5631\n",
      "Image ../data/test_samples/images/img01659_MVI_40863.jpg:\n",
      "\t+ Label: car | Confidence: 0.9083\n",
      "\t+ Label: bus | Confidence: 0.7767\n",
      "\t+ Label: van | Confidence: 0.7763\n",
      "\t+ Label: van | Confidence: 0.6053\n",
      "\t+ Label: bus | Confidence: 0.5808\n",
      "\t+ Label: car | Confidence: 0.5607\n",
      "Image ../data/test_samples/images/img01695_MVI_39361.jpg:\n",
      "\t+ Label: car | Confidence: 0.9128\n",
      "\t+ Label: car | Confidence: 0.8256\n",
      "\t+ Label: car | Confidence: 0.7108\n",
      "\t+ Label: car | Confidence: 0.5399\n",
      "\t+ Label: car | Confidence: 0.5249\n",
      "Image ../data/test_samples/images/img01722_MVI_40763.jpg:\n",
      "\t+ Label: car | Confidence: 0.7770\n",
      "\t+ Label: car | Confidence: 0.5501\n",
      "Image ../data/test_samples/images/img01831_MVI_40761.jpg:\n",
      "---- Detections were saved to: './output' ----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load detect.py\n",
    "#! /usr/bin/env python3\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from models import load_model\n",
    "from utils.utils import load_classes, rescale_boxes, non_max_suppression, print_environment_info\n",
    "from utils.datasets import ImageFolder\n",
    "from utils.transforms import Resize, DEFAULT_TRANSFORMS\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.ticker import NullLocator\n",
    "\n",
    "\n",
    "def detect_directory(model_path, weights_path, img_path, classes, output_path,\n",
    "                     batch_size=8, img_size=416, n_cpu=0, conf_thres=0.5, nms_thres=0.5):\n",
    "    \"\"\"Detects objects on all images in specified directory and saves output images with drawn detections.\n",
    "\n",
    "    :param model_path: Path to model definition file (.cfg)\n",
    "    :type model_path: str\n",
    "    :param weights_path: Path to weights or checkpoint file (.weights or .pth)\n",
    "    :type weights_path: str\n",
    "    :param img_path: Path to directory with images to inference\n",
    "    :type img_path: str\n",
    "    :param classes: List of class names\n",
    "    :type classes: [str]\n",
    "    :param output_path: Path to output directory\n",
    "    :type output_path: str\n",
    "    :param batch_size: Size of each image batch, defaults to 8\n",
    "    :type batch_size: int, optional\n",
    "    :param img_size: Size of each image dimension for yolo, defaults to 416\n",
    "    :type img_size: int, optional\n",
    "    :param n_cpu: Number of cpu threads to use during batch generation, defaults to 8\n",
    "    :type n_cpu: int, optional\n",
    "    :param conf_thres: Object confidence threshold, defaults to 0.5\n",
    "    :type conf_thres: float, optional\n",
    "    :param nms_thres: IOU threshold for non-maximum suppression, defaults to 0.5\n",
    "    :type nms_thres: float, optional\n",
    "    \"\"\"\n",
    "    dataloader = _create_data_loader(img_path, batch_size, img_size, n_cpu)\n",
    "    \n",
    "    model = load_model(model_path, weights_path=weights_path)\n",
    "    img_detections, imgs = detect(\n",
    "        model,\n",
    "        dataloader,\n",
    "        output_path,\n",
    "        conf_thres,\n",
    "        nms_thres)\n",
    "\n",
    "    _draw_and_save_output_images(\n",
    "        img_detections, imgs, img_size, output_path, classes)\n",
    "\n",
    "    print(f\"---- Detections were saved to: '{output_path}' ----\")\n",
    "\n",
    "\n",
    "def detect_image(model, image, img_size=416, conf_thres=0.5, nms_thres=0.5):\n",
    "    \"\"\"Inferences one image with model.\n",
    "\n",
    "    :param model: Model for inference\n",
    "    :type model: models.Darknet\n",
    "    :param image: Image to inference\n",
    "    :type image: nd.array\n",
    "    :param img_size: Size of each image dimension for yolo, defaults to 416\n",
    "    :type img_size: int, optional\n",
    "    :param conf_thres: Object confidence threshold, defaults to 0.5\n",
    "    :type conf_thres: float, optional\n",
    "    :param nms_thres: IOU threshold for non-maximum suppression, defaults to 0.5\n",
    "    :type nms_thres: float, optional\n",
    "    :return: Detections on image with each detection in the format: [x1, y1, x2, y2, confidence, class]\n",
    "    :rtype: nd.array\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    # Configure input\n",
    "    input_img = transforms.Compose([\n",
    "        DEFAULT_TRANSFORMS,\n",
    "        Resize(img_size)])(\n",
    "            (image, np.zeros((1, 5))))[0].unsqueeze(0)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        input_img = input_img.to(\"cuda\")\n",
    "\n",
    "    # Get detections\n",
    "    with torch.no_grad():\n",
    "        detections = model(input_img)\n",
    "        detections = non_max_suppression(detections, conf_thres, nms_thres)\n",
    "        detections = rescale_boxes(detections[0], img_size, image.shape[:2])\n",
    "    return detections.numpy()\n",
    "\n",
    "\n",
    "def detect(model, dataloader, output_path, conf_thres, nms_thres):\n",
    "    \"\"\"Inferences images with model.\n",
    "\n",
    "    :param model: Model for inference\n",
    "    :type model: models.Darknet\n",
    "    :param dataloader: Dataloader provides the batches of images to inference\n",
    "    :type dataloader: DataLoader\n",
    "    :param output_path: Path to output directory\n",
    "    :type output_path: str\n",
    "    :param conf_thres: Object confidence threshold, defaults to 0.5\n",
    "    :type conf_thres: float, optional\n",
    "    :param nms_thres: IOU threshold for non-maximum suppression, defaults to 0.5\n",
    "    :type nms_thres: float, optional\n",
    "    :return: List of detections. The coordinates are given for the padded image that is provided by the dataloader.\n",
    "        Use `utils.rescale_boxes` to transform them into the desired input image coordinate system before its transformed by the dataloader),\n",
    "        List of input image paths\n",
    "    :rtype: [Tensor], [str]\n",
    "    \"\"\"\n",
    "    # Create output directory, if missing\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "\n",
    "    img_detections = []  # Stores detections for each image index\n",
    "    imgs = []  # Stores image paths\n",
    "\n",
    "    for (img_paths, input_imgs) in tqdm.tqdm(dataloader, desc=\"Detecting\"):\n",
    "        \n",
    "        # Configure input\n",
    "        input_imgs = Variable(input_imgs.type(Tensor))\n",
    "\n",
    "        # Get detections\n",
    "        with torch.no_grad():\n",
    "            detections = model(input_imgs)\n",
    "            detections = non_max_suppression(detections, conf_thres, nms_thres)\n",
    "\n",
    "        # Store image and detections\n",
    "        img_detections.extend(detections)\n",
    "        imgs.extend(img_paths)\n",
    "    return img_detections, imgs\n",
    "\n",
    "\n",
    "def _draw_and_save_output_images(img_detections, imgs, img_size, output_path, classes):\n",
    "    \"\"\"Draws detections in output images and stores them.\n",
    "\n",
    "    :param img_detections: List of detections\n",
    "    :type img_detections: [Tensor]\n",
    "    :param imgs: List of paths to image files\n",
    "    :type imgs: [str]\n",
    "    :param img_size: Size of each image dimension for yolo\n",
    "    :type img_size: int\n",
    "    :param output_path: Path of output directory\n",
    "    :type output_path: str\n",
    "    :param classes: List of class names\n",
    "    :type classes: [str]\n",
    "    \"\"\"\n",
    "\n",
    "    # Iterate through images and save plot of detections\n",
    "    for (image_path, detections) in zip(imgs, img_detections):\n",
    "        print(f\"Image {image_path}:\")\n",
    "        _draw_and_save_output_image(\n",
    "            image_path, detections, img_size, output_path, classes)\n",
    "\n",
    "\n",
    "def _draw_and_save_output_image(image_path, detections, img_size, output_path, classes):\n",
    "    \"\"\"Draws detections in output image and stores this.\n",
    "\n",
    "    :param image_path: Path to input image\n",
    "    :type image_path: str\n",
    "    :param detections: List of detections on image\n",
    "    :type detections: [Tensor]\n",
    "    :param img_size: Size of each image dimension for yolo\n",
    "    :type img_size: int\n",
    "    :param output_path: Path of output directory\n",
    "    :type output_path: str\n",
    "    :param classes: List of class names\n",
    "    :type classes: [str]\n",
    "    \"\"\"\n",
    "    # Create plot\n",
    "    img = np.array(Image.open(image_path))\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(img)\n",
    "    # Rescale boxes to original image\n",
    "    detections = rescale_boxes(detections, img_size, img.shape[:2])\n",
    "    unique_labels = detections[:, -1].cpu().unique()\n",
    "    n_cls_preds = len(unique_labels)\n",
    "    # Bounding-box colors\n",
    "    cmap = plt.get_cmap(\"tab20b\")\n",
    "    colors = [cmap(i) for i in np.linspace(0, 1, n_cls_preds)]\n",
    "    bbox_colors = random.sample(colors, n_cls_preds)\n",
    "    for x1, y1, x2, y2, conf, cls_pred in detections:\n",
    "\n",
    "        print(f\"\\t+ Label: {classes[int(cls_pred)]} | Confidence: {conf.item():0.4f}\")\n",
    "\n",
    "        box_w = x2 - x1\n",
    "        box_h = y2 - y1\n",
    "\n",
    "        color = bbox_colors[int(np.where(unique_labels == int(cls_pred))[0])]\n",
    "        # Create a Rectangle patch\n",
    "        bbox = patches.Rectangle((x1, y1), box_w, box_h, linewidth=2, edgecolor=color, facecolor=\"none\")\n",
    "        # Add the bbox to the plot\n",
    "        ax.add_patch(bbox)\n",
    "        # Add label\n",
    "        plt.text(\n",
    "            x1,\n",
    "            y1,\n",
    "            s=classes[int(cls_pred)],\n",
    "            color=\"white\",\n",
    "            verticalalignment=\"top\",\n",
    "            bbox={\"color\": color, \"pad\": 0})\n",
    "\n",
    "    # Save generated image with detections\n",
    "    plt.axis(\"off\")\n",
    "    plt.gca().xaxis.set_major_locator(NullLocator())\n",
    "    plt.gca().yaxis.set_major_locator(NullLocator())\n",
    "    filename = os.path.basename(image_path).split(\".\")[0]\n",
    "    output_path = os.path.join(output_path, f\"{filename}.png\")\n",
    "    plt.savefig(output_path, bbox_inches=\"tight\", pad_inches=0.0)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def _create_data_loader(img_path, batch_size, img_size, n_cpu):\n",
    "    \"\"\"Creates a DataLoader for inferencing.\n",
    "\n",
    "    :param img_path: Path to file containing all paths to validation images.\n",
    "    :type img_path: str\n",
    "    :param batch_size: Size of each image batch\n",
    "    :type batch_size: int\n",
    "    :param img_size: Size of each image dimension for yolo\n",
    "    :type img_size: int\n",
    "    :param n_cpu: Number of cpu threads to use during batch generation\n",
    "    :type n_cpu: int\n",
    "    :return: Returns DataLoader\n",
    "    :rtype: DataLoader\n",
    "    \"\"\"\n",
    "    dataset = ImageFolder(\n",
    "        img_path,\n",
    "        transform=transforms.Compose([DEFAULT_TRANSFORMS, Resize(img_size)]))\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=n_cpu,\n",
    "        pin_memory=True)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "def run():\n",
    "    print_environment_info()\n",
    "    parser = argparse.ArgumentParser(description=\"Detect objects on images.\")\n",
    "    parser.add_argument(\"-m\", \"--model\", type=str, default=\"../config/yolov3-tiny.cfg\", help=\"Path to model definition file (.cfg)\")\n",
    "    parser.add_argument(\"-w\", \"--weights\", type=str, default=\"./current_yolov3.pth\", help=\"Path to weights or checkpoint file (.weights or .pth)\")\n",
    "    parser.add_argument(\"-i\", \"--images\", type=str, default=\"../data/test_samples/images\", help=\"Path to directory with images to inference\")\n",
    "    parser.add_argument(\"-c\", \"--classes\", type=str, default=\"../data/detrac.names\", help=\"Path to classes label file (.names)\")\n",
    "    parser.add_argument(\"-o\", \"--output\", type=str, default=\"./output\", help=\"Path to output directory\")\n",
    "    parser.add_argument(\"-b\", \"--batch_size\", type=int, default=1, help=\"Size of each image batch\")\n",
    "    parser.add_argument(\"--img_size\", type=int, default=416, help=\"Size of each image dimension for yolo\")\n",
    "    parser.add_argument(\"--n_cpu\", type=int, default=12, help=\"Number of cpu threads to use during batch generation\")\n",
    "    parser.add_argument(\"--conf_thres\", type=float, default=0.5, help=\"Object confidence threshold\")\n",
    "    parser.add_argument(\"--nms_thres\", type=float, default=0.5, help=\"IOU threshold for non-maximum suppression\")\n",
    "    args = parser.parse_args([])\n",
    "    print(f\"Command line arguments: {args}\")\n",
    "\n",
    "    # Extract class names from file\n",
    "    classes = load_classes(args.classes)  # List of class names\n",
    "\n",
    "    detect_directory(\n",
    "        args.model,\n",
    "        args.weights,\n",
    "        args.images,\n",
    "        classes,\n",
    "        args.output,\n",
    "        batch_size=args.batch_size,\n",
    "        img_size=args.img_size,\n",
    "        n_cpu=args.n_cpu,\n",
    "        conf_thres=args.conf_thres,\n",
    "        nms_thres=args.nms_thres)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pfs/data5/home/kit/tm/px6680/haoran/yolov3-test/test_yolov3/data/test_samples/images/img00034_MVI_39361.jpg\n"
     ]
    }
   ],
   "source": [
    "folder_path = '../data/test_samples/inference_and_test.txt'\n",
    "with open(folder_path, \"r\") as file:\n",
    "    fl = file.readlines()\n",
    "    # print(fl)\n",
    "    \n",
    "    img_path = fl[1 % len(fl)].rstrip()\n",
    "    img = np.array(\n",
    "            Image.open(img_path).convert('RGB'),\n",
    "            dtype=np.uint8)\n",
    "    print(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cth2",
   "language": "python",
   "name": "cth2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
